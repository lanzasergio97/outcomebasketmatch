{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F # All functions that don't have any parameters\n",
    "import numpy as np\n",
    "from  boxScore  import boxScore\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torch.utils.data import DataLoader # data management \n",
    "# \n",
    "\n",
    "from DatasetPrivate import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "import winsound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSEMBLE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2018-19 with traditional stats the best accuracy is 0.7 with 50 estimators and max depth 7\n",
      "For 2018-19 with advance stats the best accuracy is 0.66 with 100 estimators and max depth 6\n",
      "For 2019-20 with traditional stats the best accuracy is 0.72 with 100 estimators and max depth 14\n",
      "For 2019-20 with advance stats the best accuracy is 0.7 with 100 estimators and max depth 7\n",
      "For 2020-21 with traditional stats the best accuracy is 0.7 with 75 estimators and max depth 5\n",
      "For 2020-21 with advance stats the best accuracy is 0.68 with 100 estimators and max depth 3\n",
      "For 2021-22 with traditional stats the best accuracy is 0.68 with 150 estimators and max depth 10\n",
      "For 2021-22 with advance stats the best accuracy is 0.5 with 100 estimators and max depth 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "years_array=[\"2018-19\",\"2019-20\",\"2020-21\",\"2021-22\"]\n",
    "\n",
    "stats_array=[\"traditional\",\"advance\"]\n",
    "best_config_array=[]\n",
    "n_estimators_array=[50,75,100,150]\n",
    "for years in years_array:\n",
    "    for stats in stats_array:\n",
    "        best_acc=-1\n",
    "        best_estimators=-1\n",
    "        best_max_depth=-1\n",
    "        box_score=boxScore(years,stats)\n",
    "        x_train, x_test, y_train, y_test=box_score.separation()\n",
    "        y_train=np.array(y_train)\n",
    "        y_test=np.array(y_test)\n",
    "        for n_estimators in n_estimators_array:\n",
    "            for i in range(2,20):\n",
    "                clf=RandomForestClassifier(max_depth=i, random_state=42,n_estimators=n_estimators)\n",
    "                clf.fit(x_train,y_train)\n",
    "                prediction=clf.predict(x_test)\n",
    "                count=0\n",
    "                for x,y in zip(prediction,y_test):\n",
    "                    if(x[0]==y[0]):\n",
    "                        count+=1\n",
    "                acc=count/len(x_test)\n",
    "                if acc> best_acc:\n",
    "                    best_acc=acc\n",
    "                    best_estimators=n_estimators\n",
    "                    best_max_depth=i\n",
    "        print(\"For {} with {} stats the best accuracy is {} with {} estimators and max depth {}\".format(years,stats,best_acc,best_estimators,best_max_depth))\n",
    "        config={\n",
    "                    \"architecture\": \"RandomForest\",\n",
    "                    \"dataset\":years+\"_\"+stats,\n",
    "                    \"n_estimators\":best_estimators,\n",
    "                    \"val_acc\":best_acc,\n",
    "                    \"max_depth\":best_max_depth\n",
    "            }\n",
    "        best_config_array.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandbWriteEnsembles(project_name,best_config_array,name_runs):\n",
    "    for config in best_config_array:\n",
    "        \n",
    "        \n",
    "\n",
    "        run = wandb.init(project=project_name, config=config)\n",
    "        val_acc=config.pop(\"val_acc\")\n",
    "\n",
    "        name=name_runs\n",
    "        run.name=name\n",
    "        config = wandb.config\n",
    "        wandb.log({\n",
    "                'val_acc':val_acc\n",
    "                }\n",
    "                )\n",
    "        run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "\n",
    "for years in years_array:\n",
    "    for stats in stats_array:\n",
    "        project_name=\"T\"+stats[0:3].capitalize()+years[2:].replace(\"-\",\"\")+\"runs\"\n",
    "        wandbWriteEnsembles(project_name,best_config_array,\"radomforest\"+years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_y(y_train):\n",
    "    y_train_1d=[]\n",
    "    for el1 in y_train:\n",
    "        tmp=1\n",
    "        if(el1[0]==1):\n",
    "            tmp=0\n",
    "        y_train_1d.append(tmp)\n",
    "    return y_train_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "best_acc=-1\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "y_train_1d=transform_y(y_train)\n",
    "y_test_1d=transform_y(y_test)\n",
    "clf.fit(x_train,y_train_1d)\n",
    "prediction=clf.predict(x_test)\n",
    "count=0\n",
    "for x,y in zip(prediction,y_test_1d):\n",
    "    if(x==y):\n",
    "        count+=1\n",
    "acc=count/len(x_test)\n",
    "if acc> best_acc:\n",
    "    best_acc=acc\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2018-19 with traditional stats the best accuracy is 0.58 with 75 estimators\n",
      "For 2018-19 with advance stats the best accuracy is 0.72 with 150 estimators\n",
      "For 2019-20 with traditional stats the best accuracy is 0.78 with 75 estimators\n",
      "For 2019-20 with advance stats the best accuracy is 0.7 with 150 estimators\n",
      "For 2020-21 with traditional stats the best accuracy is 0.76 with 100 estimators\n",
      "For 2020-21 with advance stats the best accuracy is 0.74 with 100 estimators\n",
      "For 2021-22 with traditional stats the best accuracy is 0.58 with 150 estimators\n",
      "For 2021-22 with advance stats the best accuracy is 0.68 with 100 estimators\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "years_array=[\"2018-19\",\"2019-20\",\"2020-21\",\"2021-22\"]\n",
    "\n",
    "stats_array=[\"traditional\",\"advance\"]\n",
    "best_config_array=[]\n",
    "n_estimators_array=[50,75,100,150]\n",
    "for years in years_array:\n",
    "    for stats in stats_array:\n",
    "        best_acc=-1\n",
    "        best_estimators=-1\n",
    "        box_score=boxScore(years,stats)\n",
    "        x_train, x_test, y_train, y_test=box_score.separation()\n",
    "        y_train=np.array(y_train)\n",
    "        y_test=np.array(y_test)\n",
    "        for n_estimators in n_estimators_array:\n",
    "            clf = AdaBoostClassifier(n_estimators=n_estimators, random_state=42)\n",
    "            y_train_1d=transform_y(y_train)\n",
    "            y_test_1d=transform_y(y_test)\n",
    "            clf.fit(x_train,y_train_1d)\n",
    "            prediction=clf.predict(x_test)\n",
    "            count=0\n",
    "            for x,y in zip(prediction,y_test_1d):\n",
    "                if(x==y):\n",
    "                    count+=1\n",
    "            acc=count/len(x_test)\n",
    "            if acc> best_acc:\n",
    "                best_acc=acc\n",
    "                best_estimators=n_estimators\n",
    "        print(\"For {} with {} stats the best accuracy is {} with {} estimators\".format(years,stats,best_acc,best_estimators))\n",
    "        config={\n",
    "                    \"architecture\": \"Adaboost\",\n",
    "                    \"dataset\":years+\"_\"+stats,\n",
    "                    \"n_estimators\":best_estimators,\n",
    "                    \"val_acc\":best_acc\n",
    "            }\n",
    "        best_config_array.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "\n",
    "for years in years_array:\n",
    "    for stats in stats_array:\n",
    "        project_name=\"T\"+stats[0:3].capitalize()+years[2:].replace(\"-\",\"\")+\"runs\"\n",
    "        wandbWriteEnsembles(project_name,best_config_array,\"adaboost\"+years)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('pytuurc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd9d223d7b292a42db683c98874d74c150e8963ab9dd36c634c4894e65f31ff8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
