{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import externalTensor as exT\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from boxScore import boxScore\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=\"2020-21\"\n",
    "# stats=\"traditional\"\n",
    "stats='advance'\n",
    "box_score=boxScore(years,stats)\n",
    "x_train, x_test, y_train, y_test=box_score.separation()\n",
    "y_train=np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "activation=['relu','sigmoid']\n",
    "# activation=['relu']\n",
    "number_neurons=[10,30,50,100,150,200]\n",
    "# number_neurons=[10]\n",
    "possible_learning_rate=[0.0001,0.001,0.01]\n",
    "# possible_learning_rate=[0.001]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Approch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x0000015A8E578790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x0000015A8FCED4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Best model {'learning_rate': 0.0001, 'num_neurons': 10, 'acti_fun': 'sigmoid', 'loss': 0.9825, 'acc': 0.6198, 'val_loss': 0.6689, 'val_acc': 0.64}\n",
      "Best model {'learning_rate': 0.0001, 'num_neurons': 30, 'acti_fun': 'sigmoid', 'loss': 0.9953, 'acc': 0.5448, 'val_loss': 0.6656, 'val_acc': 0.66}\n",
      "Best model {'learning_rate': 0.0001, 'num_neurons': 50, 'acti_fun': 'relu', 'loss': 0.9979, 'acc': 0.0575, 'val_loss': 0.9606, 'val_acc': 0.6}\n",
      "Best model {'learning_rate': 0.0001, 'num_neurons': 100, 'acti_fun': 'relu', 'loss': 0.998, 'acc': 0.0639, 'val_loss': 0.8693, 'val_acc': 0.62}\n",
      "Best model {'learning_rate': 0.0001, 'num_neurons': 150, 'acti_fun': 'relu', 'loss': 0.998, 'acc': 0.068, 'val_loss': 0.8127, 'val_acc': 0.64}\n",
      "Best model {'learning_rate': 0.0001, 'num_neurons': 200, 'acti_fun': 'sigmoid', 'loss': 0.9977, 'acc': 0.4604, 'val_loss': 0.6632, 'val_acc': 0.62}\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "bestModelArray=[]\n",
    "\n",
    "for nN in number_neurons:\n",
    "    bestRes={'val_acc':0}\n",
    "    for el in possible_learning_rate:\n",
    "        for act in activation:\n",
    "                # Initialize model\n",
    "                model = exT.makeModel(nN,act,len(x_train.columns))\n",
    "                \n",
    "                # Instantiate an optimizer to train the model.\n",
    "                optimizer = keras.optimizers.SGD(learning_rate=el)\n",
    "                # Instantiate a loss function.\n",
    "                loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "                res={\n",
    "                    \"learning_rate\":el,\n",
    "                    'num_neurons':nN,\n",
    "                    'acti_fun':act\n",
    "                }\n",
    "                \n",
    "                model.compile(optimizer=optimizer,loss=loss_fn,metrics=['accuracy'])\n",
    "\n",
    "                res=exT.train_alternative(res,x_train,y_train,\n",
    "                    x_test, y_test, \n",
    "                    model,\n",
    "                    kf,\n",
    "                    500\n",
    "                   \n",
    "                )\n",
    "                \n",
    "                #Saved the best model based on the accuracy\n",
    "                if(res['val_acc']>bestRes['val_acc']):\n",
    "                    bestModel=model\n",
    "                    bestRes=res\n",
    "                        \n",
    "                    \n",
    "                \n",
    "    print(\"Best model\",bestRes)\n",
    "    bestModelArray.append(bestModel)\n",
    "    # f = open(\"saved_model_\"+stats+\"/summary.txt\", \"a\")\n",
    "    # tmpName=str(bestRes['num_neurons'])+\"_\"+str(bestRes['acti_fun'])+\"_\"+str(bestRes['learning_rate'])+\"_LOSS_\"+str(bestRes['loss'])+\"_ACC_\"+str(bestRes['acc'])+\"_LOSSVAL_\"+str(bestRes['val_loss'])+\"_ACCVAL_\"+str(bestRes['val_acc'])  \n",
    "    # f.write(tmpName+\"\\n\")\n",
    "    # f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save / Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myModel(neuronNumbers,activation,input_dimension):\n",
    "    \n",
    "     \n",
    "    inputs = keras.Input(shape=(input_dimension,), name=\"input\")\n",
    "    hidden = keras.layers.Dense(neuronNumbers, activation=activation,name=\"hidden\")(inputs)\n",
    "    \n",
    "    hidden1 = keras.layers.Dense(neuronNumbers*2, activation=activation,name=\"hidden1\")(hidden)\n",
    "    droput= keras.layers.Dropout(.1,input_shape=(input_dimension,))(hidden1)\n",
    "    outputs = keras.layers.Dense(2,activation=tf.keras.activations.softmax ,name=\"predictions\")(droput)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestModelArray[2].save(\"saved_model_\"+stats+\"/\"+\"bestModel\")\n",
    "model = tf.keras.models.load_model('saved_model_'+stats+'/bestModel') \n",
    "validation_data=(np.asarray(x_test),np.asarray(y_test))  \n",
    "gg=model.evaluate(np.asarray(x_test),np.asarray(y_test),batch_size=200)\n",
    "print(\"Validation accuracy\",gg[1])\n",
    "# model.summary()\n",
    "newModel=myModel(50,\"relu\",len(x_train.columns))\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.001)\n",
    "                \n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "newModel.compile(optimizer=optimizer,loss=loss_fn,metrics=['accuracy'])\n",
    "res=newModel.fit(x_train,y_train,batch_size=200,validation_data=(np.asarray(x_test),np.asarray(y_test)),verbose=False,epochs=500)\n",
    "print(res.history[\"accuracy\"][-1])\n",
    "print(res.history[\"val_accuracy\"][-1])\n",
    "# newModel.evaluate(,batch_size=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 624us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "157/157 [==============================] - 0s 636us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "157/157 [==============================] - 0s 603us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "157/157 [==============================] - 0s 615us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from locale import atof\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('saved_model_'+stats+'/bestModel') \n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "                        training_data=np.array(x_train),\n",
    "                        feature_names=x_train.columns,\n",
    "                        class_names=['win first team', 'win second team'],\n",
    "                        mode='classification'\n",
    "                    )\n",
    "answer=[]\n",
    "\n",
    "list_index=[0,1,2,6]\n",
    "# list_index=[6]\n",
    "big_one=[]\n",
    "for i in list_index:\n",
    "    r=np.asarray(x_test)\n",
    "    exp = explainer.explain_instance(\n",
    "                data_row=x_test.iloc[i], \n",
    "                predict_fn=model.predict\n",
    "            )\n",
    "    prediction=model.predict(r[i][None,...])\n",
    "    \n",
    "    boolean_vector=np.rint(prediction)==y_test[i]\n",
    "    value_boolean_dictionary=boolean_vector.all()\n",
    "\n",
    "\n",
    "\n",
    "    res=exp.as_list()\n",
    "   \n",
    "    tmp=np.array(res)\n",
    "    value_predestination=tmp[:,1].astype(float)\n",
    "    total_sum_abs=np.sum( np.abs(value_predestination))\n",
    "    tec=(value_predestination)/total_sum_abs\n",
    "    \n",
    "    \n",
    "\n",
    "    string_predestination=tmp[:,0]\n",
    "    \n",
    "    answer=[ [x,z] for x,z in zip(string_predestination,tec)]\n",
    "    \n",
    "\n",
    "    dict=[]\n",
    "    for count,ele in enumerate(string_predestination[0:4]):\n",
    "        ecc=ele.split()\n",
    "        range_div=[]\n",
    "        for el in ecc:\n",
    "            if el[0].isalpha():\n",
    "                word=el\n",
    "            else:\n",
    "                if el!='<' and el!='<=' and el!='>=' and el!='>':\n",
    "                    range_div.append(atof(el))\n",
    "\n",
    "        dict.append([(range_div[0],range_div[1]),word,tec[count],value_boolean_dictionary])\n",
    "    big_one.append(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Range</th>\n",
       "      <th>Stats</th>\n",
       "      <th>Percentage of decision</th>\n",
       "      <th>Correct prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(109.45, 117.0)</td>\n",
       "      <td>OFF_RATING</td>\n",
       "      <td>-0.181291</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(101.9, 109.1)</td>\n",
       "      <td>OFF_RATING_O</td>\n",
       "      <td>-0.172608</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(109.1, 117.53)</td>\n",
       "      <td>OFF_RATING_O</td>\n",
       "      <td>0.227653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(109.45, 117.0)</td>\n",
       "      <td>OFF_RATING</td>\n",
       "      <td>-0.167011</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(101.9, 109.45)</td>\n",
       "      <td>OFF_RATING</td>\n",
       "      <td>0.208852</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(109.1, 117.53)</td>\n",
       "      <td>OFF_RATING_O</td>\n",
       "      <td>0.19711</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(101.9, 109.45)</td>\n",
       "      <td>OFF_RATING</td>\n",
       "      <td>0.20163</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(109.1, 117.53)</td>\n",
       "      <td>OFF_RATING_O</td>\n",
       "      <td>0.162764</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Range         Stats Percentage of decision Correct prediction\n",
       "0   (109.45, 117.0)    OFF_RATING              -0.181291               True\n",
       "2    (101.9, 109.1)  OFF_RATING_O              -0.172608               True\n",
       "4   (109.1, 117.53)  OFF_RATING_O               0.227653               True\n",
       "5   (109.45, 117.0)    OFF_RATING              -0.167011               True\n",
       "8   (101.9, 109.45)    OFF_RATING               0.208852               True\n",
       "9   (109.1, 117.53)  OFF_RATING_O                0.19711               True\n",
       "12  (101.9, 109.45)    OFF_RATING                0.20163              False\n",
       "14  (109.1, 117.53)  OFF_RATING_O               0.162764              False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_one=np.array(big_one)\n",
    "big_one.reshape(16,4)\n",
    "big_one.reshape(-1)\n",
    "result=pd.DataFrame(big_one)\n",
    "result.columns=[\"Range\",\"Stats\", \"Percentage of decision\", \"Correct prediction\"]\n",
    "result[result[\"Stats\"].str.contains(\"OFF_RATING\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion=[]\n",
    "absvalue=[]\n",
    "counts={}\n",
    "oblio=0\n",
    "for list in answer:\n",
    "    for el in list[0:4]:\n",
    "        \n",
    "        stat=[word for word in el[0].split() if word[0].isalpha()] \n",
    "        conclusion.append([stat[0],abs(el[1])])\n",
    "        if stat[0]  not in counts: \n",
    "            counts[stat[0]]=abs(el[1])\n",
    "        else:\n",
    "            \n",
    "            counts[stat[0]]=counts.get(stat[0])+abs(el[1])\n",
    "\n",
    "    oblio=1\n",
    "\n",
    "\n",
    "sortdict = dict(sorted(counts.items(), key=lambda x:x[1],reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sortdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "//Create two corpus one's for right prediction ones for wrong, understand the better range for both decision making  \n",
    "\n",
    "Re-inizialiate the net with just the four main adv split (defense_rating, offensive_rating for both team)\n",
    "\n",
    "Try this process also for tradional split \n",
    "\n",
    "Looking for a new tool? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impression\n",
    "\n",
    "Understand if it's possible improve the accuracy/network\n",
    "\n",
    "Manage Lime Tool to understand better the network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('BasketScripts': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f61b42334e39087fcf873d4b58ce314af401b80aed031fb5917bf158a5bb3c56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
